{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-20T14:27:38.219762Z","iopub.execute_input":"2023-01-20T14:27:38.220097Z","iopub.status.idle":"2023-01-20T14:27:38.230856Z","shell.execute_reply.started":"2023-01-20T14:27:38.220059Z","shell.execute_reply":"2023-01-20T14:27:38.229677Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/shakespeare/shakespeare.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generating Shakespearean Text with Character Based RNNs\n\nProblem Statement: Given a character or sequence of characters, we want to predict the next character at each time step. Model is trained to follow a language similar to the works of Shakespeare. The tinyshakespear dataset is used for training.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport nltk\nimport os\nimport time","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2023-01-20T14:27:49.088692Z","iopub.execute_input":"2023-01-20T14:27:49.089008Z","iopub.status.idle":"2023-01-20T14:27:55.323907Z","shell.execute_reply.started":"2023-01-20T14:27:49.088980Z","shell.execute_reply":"2023-01-20T14:27:55.323007Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"dataset = open('/kaggle/input/shakespeare/shakespeare.txt', 'r').read() ","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:28:08.166192Z","iopub.execute_input":"2023-01-20T14:28:08.166622Z","iopub.status.idle":"2023-01-20T14:28:08.172917Z","shell.execute_reply.started":"2023-01-20T14:28:08.166588Z","shell.execute_reply":"2023-01-20T14:28:08.171924Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"text = dataset[37:]","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:30:24.262169Z","iopub.execute_input":"2023-01-20T14:30:24.262517Z","iopub.status.idle":"2023-01-20T14:30:24.266343Z","shell.execute_reply.started":"2023-01-20T14:30:24.262487Z","shell.execute_reply":"2023-01-20T14:30:24.265444Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"vocabulary = list(sorted(set(text)))\nprint('No. of unique characters: {}'.format(len(vocabulary)))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:30:25.603887Z","iopub.execute_input":"2023-01-20T14:30:25.604205Z","iopub.status.idle":"2023-01-20T14:30:25.611009Z","shell.execute_reply.started":"2023-01-20T14:30:25.604169Z","shell.execute_reply":"2023-01-20T14:30:25.609690Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"No. of unique characters: 61\n","output_type":"stream"}]},{"cell_type":"code","source":"# text =text.lower()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:30:27.663777Z","iopub.execute_input":"2023-01-20T14:30:27.664103Z","iopub.status.idle":"2023-01-20T14:30:27.668275Z","shell.execute_reply.started":"2023-01-20T14:30:27.664072Z","shell.execute_reply":"2023-01-20T14:30:27.667082Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Text","metadata":{}},{"cell_type":"code","source":"\nchar_to_index = dict((c,i) for (i,c) in enumerate(vocabulary))\nprint(char_to_index)\nint_text = np.array([char_to_index[i] for i in text])\n\nindex_to_char = np.array(vocabulary)\nprint(index_to_char)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:30:29.480073Z","iopub.execute_input":"2023-01-20T14:30:29.480424Z","iopub.status.idle":"2023-01-20T14:30:29.504245Z","shell.execute_reply.started":"2023-01-20T14:30:29.480391Z","shell.execute_reply":"2023-01-20T14:30:29.503034Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, ':': 9, ';': 10, '?': 11, 'A': 12, 'B': 13, 'C': 14, 'D': 15, 'E': 16, 'F': 17, 'G': 18, 'H': 19, 'I': 20, 'J': 21, 'K': 22, 'L': 23, 'M': 24, 'N': 25, 'O': 26, 'P': 27, 'R': 28, 'S': 29, 'T': 30, 'U': 31, 'V': 32, 'W': 33, 'Y': 34, 'a': 35, 'b': 36, 'c': 37, 'd': 38, 'e': 39, 'f': 40, 'g': 41, 'h': 42, 'i': 43, 'j': 44, 'k': 45, 'l': 46, 'm': 47, 'n': 48, 'o': 49, 'p': 50, 'q': 51, 'r': 52, 's': 53, 't': 54, 'u': 55, 'v': 56, 'w': 57, 'x': 58, 'y': 59, 'z': 60}\n['\\n' ' ' '!' \"'\" '(' ')' ',' '-' '.' ':' ';' '?' 'A' 'B' 'C' 'D' 'E' 'F'\n 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'R' 'S' 'T' 'U' 'V' 'W' 'Y' 'a'\n 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's'\n 't' 'u' 'v' 'w' 'x' 'y' 'z']\n","output_type":"stream"}]},{"cell_type":"code","source":"int_text.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:32:48.537295Z","iopub.execute_input":"2023-01-20T14:32:48.537648Z","iopub.status.idle":"2023-01-20T14:32:48.543470Z","shell.execute_reply.started":"2023-01-20T14:32:48.537618Z","shell.execute_reply":"2023-01-20T14:32:48.542429Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(94238,)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Create Training Data","metadata":{}},{"cell_type":"code","source":"seq_length= 40 \n\nexamples_per_epoch = len(text)\n\nchar_dataset = tf.data.Dataset.from_tensor_slices(int_text)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:33:10.680422Z","iopub.execute_input":"2023-01-20T14:33:10.680766Z","iopub.status.idle":"2023-01-20T14:33:12.607976Z","shell.execute_reply.started":"2023-01-20T14:33:10.680736Z","shell.execute_reply":"2023-01-20T14:33:12.607095Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sequences = char_dataset.batch(seq_length+1, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:33:51.433584Z","iopub.execute_input":"2023-01-20T14:33:51.434000Z","iopub.status.idle":"2023-01-20T14:33:51.441164Z","shell.execute_reply.started":"2023-01-20T14:33:51.433963Z","shell.execute_reply":"2023-01-20T14:33:51.440351Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# sequences","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:34:19.606645Z","iopub.execute_input":"2023-01-20T14:34:19.606976Z","iopub.status.idle":"2023-01-20T14:34:19.613061Z","shell.execute_reply.started":"2023-01-20T14:34:19.606945Z","shell.execute_reply":"2023-01-20T14:34:19.611993Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<BatchDataset shapes: (41,), types: tf.int64>"},"metadata":{}}]},{"cell_type":"code","source":"#Testing\nprint(\"Character Stream: \\n\")\nfor i in char_dataset.take(10):\n  print(index_to_char[i.numpy()])  \n\nprint(\"\\nSequence: \\n\")\nfor i in sequences.take(10):\n  print(repr(''.join(index_to_char[i.numpy()])))  #use repr() for more clarity. str() keeps formatting it","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:35:09.329584Z","iopub.execute_input":"2023-01-20T14:35:09.329937Z","iopub.status.idle":"2023-01-20T14:35:09.394075Z","shell.execute_reply.started":"2023-01-20T14:35:09.329904Z","shell.execute_reply":"2023-01-20T14:35:09.393028Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Character Stream: \n\nF\nr\no\nm\n \nf\na\ni\nr\ne\n\nSequence: \n\n'From fairest creatures we desire increase'\n\",\\nThat thereby beauty's rose might never \"\n'die,\\nBut as the riper should by time dece'\n'ase,\\nHis tender heir might bear his memor'\n'y:\\nBut thou contracted to thine own brigh'\n\"t eyes,\\nFeed'st thy light's flame with se\"\n'lf-substantial fuel,\\nMaking a famine wher'\n'e abundance lies,\\nThy self thy foe, to th'\n'y sweet self too cruel:\\nThou that art now'\n\" the world's fresh ornament,\\nAnd only her\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\nTarget value: for each sequence of characters, we return that sequence, shifted one position to the right, along with the new character that is predicted to follow the sequence.\n\nTo create training examples of (input, target) pairs, we take the given sequence. The input is sequence with last word removed. Target is sequence with first word removed. Example: sequence: abc d ef input: abc d e target: bc d ef","metadata":{}},{"cell_type":"code","source":"def create_input_target_pair(chunk):\n    input_text = chunk[:-1]\n    target_text = chunk[1:]\n    return input_text, target_text\n\ndataset = sequences.map(create_input_target_pair)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:16.578119Z","iopub.execute_input":"2023-01-20T14:37:16.578472Z","iopub.status.idle":"2023-01-20T14:37:16.659050Z","shell.execute_reply.started":"2023-01-20T14:37:16.578440Z","shell.execute_reply":"2023-01-20T14:37:16.658282Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"#Testing\nfor input_example, target_example in  dataset.take(1):\n  print ('Input data: ', repr(''.join(index_to_char[input_example.numpy()])))\n  print ('Target data:', repr(''.join(index_to_char[target_example.numpy()])))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:16.917570Z","iopub.execute_input":"2023-01-20T14:37:16.917918Z","iopub.status.idle":"2023-01-20T14:37:16.971599Z","shell.execute_reply.started":"2023-01-20T14:37:16.917887Z","shell.execute_reply":"2023-01-20T14:37:16.970839Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Input data:  'From fairest creatures we desire increas'\nTarget data: 'rom fairest creatures we desire increase'\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE = 64\nBUFFER_SIZE = 10000\ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:17.640105Z","iopub.execute_input":"2023-01-20T14:37:17.640448Z","iopub.status.idle":"2023-01-20T14:37:17.650533Z","shell.execute_reply.started":"2023-01-20T14:37:17.640415Z","shell.execute_reply":"2023-01-20T14:37:17.649419Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<BatchDataset shapes: ((64, 40), (64, 40)), types: (tf.int64, tf.int64)>"},"metadata":{}}]},{"cell_type":"markdown","source":"\\## Building the Model","metadata":{}},{"cell_type":"code","source":"vocab_size = len(vocabulary)\nembedding_dim = 256\nrnn_units= 1024","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:23.828968Z","iopub.execute_input":"2023-01-20T14:37:23.829350Z","iopub.status.idle":"2023-01-20T14:37:23.833619Z","shell.execute_reply.started":"2023-01-20T14:37:23.829292Z","shell.execute_reply":"2023-01-20T14:37:23.832602Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"3 Layers used:\n\nInput Layer: Maps character to 256 dimension vector\n\nGRU Layer: RNN of size 1024\n\nDense Layer: Output with same size as vocabulary\n\nSince it is a character level RNN, we can use keras.Sequential model (All layers have single input and single output).","metadata":{}},{"cell_type":"code","source":"def build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size):\n    model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n                              batch_input_shape=[batch_size, None]),\n    tf.keras.layers.LSTM(rnn_units, \n                        return_sequences=True,\n                        stateful=True,\n                        recurrent_initializer='glorot_uniform'),\n    tf.keras.layers.Dense(vocab_size)\n  ])\n    return model\n\n# Reference for theory: https://jhui.github.io/2017/03/15/RNN-LSTM-GRU/","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:27.326083Z","iopub.execute_input":"2023-01-20T14:37:27.326467Z","iopub.status.idle":"2023-01-20T14:37:27.332405Z","shell.execute_reply.started":"2023-01-20T14:37:27.326431Z","shell.execute_reply":"2023-01-20T14:37:27.331461Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"lstm_model = build_model_lstm(\n  vocab_size = vocab_size,\n  embedding_dim=embedding_dim,\n  rnn_units=rnn_units,\n  batch_size=BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:44.251656Z","iopub.execute_input":"2023-01-20T14:37:44.251997Z","iopub.status.idle":"2023-01-20T14:37:44.853882Z","shell.execute_reply.started":"2023-01-20T14:37:44.251964Z","shell.execute_reply":"2023-01-20T14:37:44.852980Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"#Testing: shape\nfor input_example_batch, target_example_batch in dataset.take(1):\n    example_prediction = lstm_model(input_example_batch)\n    assert (example_prediction.shape == (BATCH_SIZE, seq_length, vocab_size)), \"Shape error\"\n    #print(example_prediction.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:44.855450Z","iopub.execute_input":"2023-01-20T14:37:44.855789Z","iopub.status.idle":"2023-01-20T14:37:47.575060Z","shell.execute_reply.started":"2023-01-20T14:37:44.855753Z","shell.execute_reply":"2023-01-20T14:37:47.574114Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"#model.summary() \n#check shapes if necessary","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:47.576920Z","iopub.execute_input":"2023-01-20T14:37:47.577265Z","iopub.status.idle":"2023-01-20T14:37:47.581067Z","shell.execute_reply.started":"2023-01-20T14:37:47.577236Z","shell.execute_reply":"2023-01-20T14:37:47.579921Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"sampled_indices = tf.random.categorical(example_prediction[0], num_samples=1)\nsampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:47.582670Z","iopub.execute_input":"2023-01-20T14:37:47.583252Z","iopub.status.idle":"2023-01-20T14:37:47.599848Z","shell.execute_reply.started":"2023-01-20T14:37:47.583209Z","shell.execute_reply":"2023-01-20T14:37:47.598820Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"def loss(labels, logits):\n    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n\n#Loss Function reference: https://www.dlology.com/blog/how-to-use-keras-sparse_categorical_crossentropy/\n\nexample_loss  = loss(target_example_batch, example_prediction)\nprint(\"Prediction shape: \", example_prediction.shape)\nprint(\"Loss:      \", example_loss.numpy().mean())","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:48.880077Z","iopub.execute_input":"2023-01-20T14:37:48.880434Z","iopub.status.idle":"2023-01-20T14:37:48.897227Z","shell.execute_reply.started":"2023-01-20T14:37:48.880402Z","shell.execute_reply":"2023-01-20T14:37:48.896273Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Prediction shape:  (64, 40, 61)\nLoss:       4.109836\n","output_type":"stream"}]},{"cell_type":"code","source":"lstm_model.compile(optimizer='adam', loss=loss)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:54.136243Z","iopub.execute_input":"2023-01-20T14:37:54.136630Z","iopub.status.idle":"2023-01-20T14:37:54.152801Z","shell.execute_reply.started":"2023-01-20T14:37:54.136596Z","shell.execute_reply":"2023-01-20T14:37:54.151916Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"lstm_dir_checkpoints= './training_checkpoints_LSTM'\ncheckpoint_prefix = os.path.join(lstm_dir_checkpoints, \"checkpt_{epoch}\") #name\ncheckpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:37:54.485457Z","iopub.execute_input":"2023-01-20T14:37:54.485812Z","iopub.status.idle":"2023-01-20T14:37:54.491297Z","shell.execute_reply.started":"2023-01-20T14:37:54.485779Z","shell.execute_reply":"2023-01-20T14:37:54.490070Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"EPOCHS=100 #increase number of epochs for better results (lesser loss)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:38:04.716437Z","iopub.execute_input":"2023-01-20T14:38:04.716756Z","iopub.status.idle":"2023-01-20T14:38:04.721755Z","shell.execute_reply.started":"2023-01-20T14:38:04.716726Z","shell.execute_reply":"2023-01-20T14:38:04.720781Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"history = lstm_model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:39:42.034728Z","iopub.execute_input":"2023-01-20T14:39:42.035109Z","iopub.status.idle":"2023-01-20T14:41:38.514347Z","shell.execute_reply.started":"2023-01-20T14:39:42.035076Z","shell.execute_reply":"2023-01-20T14:41:38.513425Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1/100\n35/35 [==============================] - 1s 28ms/step - loss: 3.3371\nEpoch 2/100\n35/35 [==============================] - 1s 26ms/step - loss: 2.8657\nEpoch 3/100\n35/35 [==============================] - 1s 26ms/step - loss: 2.5391\nEpoch 4/100\n35/35 [==============================] - 1s 26ms/step - loss: 2.3212\nEpoch 5/100\n35/35 [==============================] - 1s 26ms/step - loss: 2.2272\nEpoch 6/100\n35/35 [==============================] - 1s 26ms/step - loss: 2.1615\nEpoch 7/100\n35/35 [==============================] - 1s 25ms/step - loss: 2.0945\nEpoch 8/100\n35/35 [==============================] - 1s 25ms/step - loss: 2.0323\nEpoch 9/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.9719\nEpoch 10/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.9201\nEpoch 11/100\n35/35 [==============================] - 1s 28ms/step - loss: 1.8725\nEpoch 12/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.8254\nEpoch 13/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.7882\nEpoch 14/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.7544\nEpoch 15/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.7205\nEpoch 16/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.6904\nEpoch 17/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.6631\nEpoch 18/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.6355\nEpoch 19/100\n35/35 [==============================] - 1s 28ms/step - loss: 1.6065\nEpoch 20/100\n35/35 [==============================] - 1s 29ms/step - loss: 1.5836\nEpoch 21/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.5550\nEpoch 22/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.5284\nEpoch 23/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.5039\nEpoch 24/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.4807\nEpoch 25/100\n35/35 [==============================] - 1s 30ms/step - loss: 1.4536\nEpoch 26/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.4270\nEpoch 27/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.4026\nEpoch 28/100\n35/35 [==============================] - 1s 29ms/step - loss: 1.3755\nEpoch 29/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.3471\nEpoch 30/100\n35/35 [==============================] - 1s 28ms/step - loss: 1.3219\nEpoch 31/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.2909\nEpoch 32/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.2613\nEpoch 33/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.2288\nEpoch 34/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.1929\nEpoch 35/100\n35/35 [==============================] - 1s 31ms/step - loss: 1.1611\nEpoch 36/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.1248\nEpoch 37/100\n35/35 [==============================] - 1s 26ms/step - loss: 1.0890\nEpoch 38/100\n35/35 [==============================] - 1s 29ms/step - loss: 1.0492\nEpoch 39/100\n35/35 [==============================] - 1s 27ms/step - loss: 1.0103\nEpoch 40/100\n35/35 [==============================] - 1s 31ms/step - loss: 0.9690\nEpoch 41/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.9322\nEpoch 42/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.8933\nEpoch 43/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.8532\nEpoch 44/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.8140\nEpoch 45/100\n35/35 [==============================] - 1s 29ms/step - loss: 0.7759\nEpoch 46/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.7376\nEpoch 47/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.7086\nEpoch 48/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.6793\nEpoch 49/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.6504\nEpoch 50/100\n35/35 [==============================] - 1s 30ms/step - loss: 0.6265\nEpoch 51/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.5973\nEpoch 52/100\n35/35 [==============================] - 1s 31ms/step - loss: 0.5766\nEpoch 53/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.5568\nEpoch 54/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.5375\nEpoch 55/100\n35/35 [==============================] - 1s 28ms/step - loss: 0.5219\nEpoch 56/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.5081\nEpoch 57/100\n35/35 [==============================] - 1s 28ms/step - loss: 0.4989\nEpoch 58/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.4800\nEpoch 59/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.4726\nEpoch 60/100\n35/35 [==============================] - 1s 28ms/step - loss: 0.4620\nEpoch 61/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.4496\nEpoch 62/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.4430\nEpoch 63/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.4387\nEpoch 64/100\n35/35 [==============================] - 1s 29ms/step - loss: 0.4286\nEpoch 65/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.4233\nEpoch 66/100\n35/35 [==============================] - 1s 28ms/step - loss: 0.4159\nEpoch 67/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.4071\nEpoch 68/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.4040\nEpoch 69/100\n35/35 [==============================] - 1s 37ms/step - loss: 0.3976\nEpoch 70/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3921\nEpoch 71/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3914\nEpoch 72/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3823\nEpoch 73/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3771\nEpoch 74/100\n35/35 [==============================] - 1s 28ms/step - loss: 0.3769\nEpoch 75/100\n35/35 [==============================] - 1s 29ms/step - loss: 0.3741\nEpoch 76/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3682\nEpoch 77/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3662\nEpoch 78/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3599\nEpoch 79/100\n35/35 [==============================] - 1s 37ms/step - loss: 0.3597\nEpoch 80/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3536\nEpoch 81/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3518\nEpoch 82/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3488\nEpoch 83/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3448\nEpoch 84/100\n35/35 [==============================] - 1s 29ms/step - loss: 0.3421\nEpoch 85/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3417\nEpoch 86/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3382\nEpoch 87/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3331\nEpoch 88/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3347\nEpoch 89/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3309\nEpoch 90/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3275\nEpoch 91/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3246\nEpoch 92/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3232\nEpoch 93/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3254\nEpoch 94/100\n35/35 [==============================] - 1s 32ms/step - loss: 0.3200\nEpoch 95/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3180\nEpoch 96/100\n35/35 [==============================] - 1s 26ms/step - loss: 0.3168\nEpoch 97/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3149\nEpoch 98/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3110\nEpoch 99/100\n35/35 [==============================] - 1s 28ms/step - loss: 0.3098\nEpoch 100/100\n35/35 [==============================] - 1s 27ms/step - loss: 0.3107\n","output_type":"stream"}]},{"cell_type":"code","source":"tf.train.latest_checkpoint(lstm_dir_checkpoints)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:41:38.516108Z","iopub.execute_input":"2023-01-20T14:41:38.516389Z","iopub.status.idle":"2023-01-20T14:41:38.528809Z","shell.execute_reply.started":"2023-01-20T14:41:38.516362Z","shell.execute_reply":"2023-01-20T14:41:38.527617Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'./training_checkpoints_LSTM/checkpt_100'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Prediction","metadata":{}},{"cell_type":"code","source":"lstm_model = build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size=1)\nlstm_model.load_weights(tf.train.latest_checkpoint(lstm_dir_checkpoints))\nlstm_model.build(tf.TensorShape([1, None]))\n\nlstm_model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:41:41.860712Z","iopub.execute_input":"2023-01-20T14:41:41.861034Z","iopub.status.idle":"2023-01-20T14:41:42.133937Z","shell.execute_reply.started":"2023-01-20T14:41:41.861004Z","shell.execute_reply":"2023-01-20T14:41:42.133018Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (1, None, 256)            15616     \n_________________________________________________________________\nlstm_1 (LSTM)                (1, None, 1024)           5246976   \n_________________________________________________________________\ndense_1 (Dense)              (1, None, 61)             62525     \n=================================================================\nTotal params: 5,325,117\nTrainable params: 5,325,117\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_text(model, start_string):\n    num_generate = 1000 #Number of characters to be generated\n\n    input_eval = [char_to_index[s] for s in start_string] #vectorising input\n    input_eval = tf.expand_dims(input_eval, 0)\n\n    text_generated = []\n\n    # Low temperatures results in more predictable text.\n    # Higher temperatures results in more surprising text.\n    # Experiment to find the best setting.\n    temperature = 0.5\n\n    # Here batch size == 1\n    model.reset_states()\n    for i in range(num_generate):\n        predictions = model(input_eval)\n        # remove the batch dimension\n        predictions = tf.squeeze(predictions, 0)\n\n        # using a categorical distribution to predict the character returned by the model\n        predictions = predictions / temperature\n        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n\n        # We pass the predicted character as the next input to the model\n        # along with the previous hidden state\n        input_eval = tf.expand_dims([predicted_id], 0)\n\n        text_generated.append(index_to_char[predicted_id])\n\n    return (start_string + ''.join(text_generated))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:41:43.381095Z","iopub.execute_input":"2023-01-20T14:41:43.381455Z","iopub.status.idle":"2023-01-20T14:41:43.390014Z","shell.execute_reply.started":"2023-01-20T14:41:43.381409Z","shell.execute_reply":"2023-01-20T14:41:43.388607Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#Testing\n#print(generate_text(lstm_model, start_string=u\"ROMEO: \"))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:41:44.341650Z","iopub.execute_input":"2023-01-20T14:41:44.342009Z","iopub.status.idle":"2023-01-20T14:41:44.349002Z","shell.execute_reply.started":"2023-01-20T14:41:44.341975Z","shell.execute_reply":"2023-01-20T14:41:44.347521Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#Prediction with User Input\nlstm_test = input(\"Enter your starting string: \")\nprint(generate_text(lstm_model, start_string=lstm_test))\n","metadata":{"execution":{"iopub.status.busy":"2023-01-20T14:41:45.663321Z","iopub.execute_input":"2023-01-20T14:41:45.663642Z","iopub.status.idle":"2023-01-20T14:41:55.953905Z","shell.execute_reply.started":"2023-01-20T14:41:45.663609Z","shell.execute_reply":"2023-01-20T14:41:55.952910Z"},"trusted":true},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your starting string:  You live\n"},{"name":"stdout","text":"You live in this poor rhyme,\nWhile he will not every hour survey,\nFor blunting age dead?\nNo, neither he, nor his compeers bareness every where:\nThou mayst call thine own self bring:\nAnd what is's deceives repose laid to make the taker mad.\nMad in perfection but a little moment.\nThat thou in losing me, shalt win much outly gays,\nAnd make me bow,\nAnd do not drop in for my sin, grounded on sinful loving,\nO if (I say) you look upon this verse,\nAs every alien pen hath got my use it might unused stay\nFrom far worsing things:\nAlas why fearing of time's ty my sun one early morn did shine eye,\nWhen love converted from thee,  \nWhilst I thou wilt, for I being pent in thee,\nPer for my love, not for their rhyme,\nExce compound sweet; forgoing simple savour,\nWhich huld all my poor beast then find,\nWhen swift eyes can see,\nSo long lives this, and disgrace.\nTherefore my mistress' eyes are restored in the basest clouds to ride,\nWith ught,\nIn dis a healthful remedy,\nFor men discased, but shall carry me away,\nMy \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}